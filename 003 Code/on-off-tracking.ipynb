{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# import cv2\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# from collections import defaultdict\n",
    "# from ultralytics import YOLO\n",
    "# from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# CONFIDENCE_THRESHOLD = 0.5\n",
    "# GREEN = (0, 255, 0)\n",
    "# WHITE = (255, 255, 255)\n",
    "# RED = (0, 0, 255)\n",
    "\n",
    "# # 클래스 정보 입력\n",
    "# with open('/Users/kimhyeonjeong/Documents/2024-2/OD/code/yolo_class.txt', 'r') as coco128:\n",
    "#     class_list = coco128.read().split('\\n')\n",
    "\n",
    "# # YOLO 모델과 DeepSort 초기화\n",
    "# model = YOLO('/Users/kimhyeonjeong/Documents/2024-2/OD/code/best.pt')\n",
    "# tracker = DeepSort(max_age=50)\n",
    "\n",
    "# # 이미지 폴더 설정\n",
    "# image_folder_path = '/Users/kimhyeonjeong/Documents/2024-2/OD/code/bel12'  # 이미지 폴더 경로\n",
    "# file_names = os.listdir(image_folder_path)\n",
    "# image_files = [f for f in file_names if f.endswith(('.jpg', '.png'))]\n",
    "# image_files.sort()\n",
    "\n",
    "# # 트래킹 ID 및 라이트 RGB 기록을 저장할 딕셔너리 초기화\n",
    "# class_track_ids = {}\n",
    "# light_rgb_history = defaultdict(list)\n",
    "\n",
    "# # 비디오 저장 설정\n",
    "# output_video_path = '/Users/kimhyeonjeong/Documents/2024-2/OD/code/output/bel12_output.mp4'\n",
    "# frame_width, frame_height = cv2.imread(os.path.join(image_folder_path, image_files[0])).shape[1], cv2.imread(os.path.join(image_folder_path, image_files[0])).shape[0]\n",
    "# out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), 30.0, (frame_width, frame_height))\n",
    "\n",
    "# # 이미지 순차 처리\n",
    "# frame_count = 0\n",
    "# for image_file in image_files:\n",
    "#     image_path = os.path.join(image_folder_path, image_file)\n",
    "#     frame = cv2.imread(image_path)\n",
    "#     if frame is None:\n",
    "#         print(f\"Warning: Could not load image {image_file}\")\n",
    "#         continue\n",
    "\n",
    "#     # 프레임 처리 시작 시간\n",
    "#     start = datetime.datetime.now()\n",
    "\n",
    "#     # YOLO 모델을 사용하여 객체 감지 수행\n",
    "#     detection = model.predict(source=[frame], save=False)[0]\n",
    "#     results = []\n",
    "\n",
    "#     for data in detection.boxes.data.tolist():  # data : [xmin, ymin, xmax, ymax, confidence_score, class_id]\n",
    "#         confidence = float(data[4])\n",
    "#         if confidence < CONFIDENCE_THRESHOLD:\n",
    "#             continue\n",
    "\n",
    "#         xmin, ymin, xmax, ymax = int(data[0]), int(data[1]), int(data[2]), int(data[3])\n",
    "#         width = xmax - xmin\n",
    "#         height = ymax - ymin\n",
    "#         label = int(data[5])\n",
    "#         class_name = class_list[label]\n",
    "\n",
    "#         # 클래스별 트래킹 ID 관리\n",
    "#         if class_name not in class_track_ids:\n",
    "#             class_track_ids[class_name] = {}\n",
    "\n",
    "#         bbox = (xmin, ymin, width, height)\n",
    "#         results.append([bbox, confidence, label])\n",
    "\n",
    "#     # DeepSort를 사용하여 트래킹 업데이트\n",
    "#     tracks = tracker.update_tracks(results, frame=frame)\n",
    "\n",
    "#     # 자동차 및 라이트 바운딩 박스 추출\n",
    "#     car_boxes = []\n",
    "#     light_boxes = []\n",
    "#     light_ids_rgb = []\n",
    "#     for track in tracks:\n",
    "#         if not track.is_confirmed():\n",
    "#             continue\n",
    "\n",
    "#         track_id = track.track_id\n",
    "#         ltrb = track.to_ltrb()\n",
    "#         label = track.det_class\n",
    "#         class_name = class_list[label]\n",
    "\n",
    "#         # 트래킹 ID 할당\n",
    "#         if track_id not in class_track_ids[class_name]:\n",
    "#             class_track_ids[class_name][track_id] = f\"{class_name}-{len(class_track_ids[class_name]) + 1}\"\n",
    "\n",
    "#         assigned_id = class_track_ids[class_name][track_id]\n",
    "\n",
    "#         xmin, ymin, xmax, ymax = int(ltrb[0]), int(ltrb[1]), int(ltrb[2]), int(ltrb[3])\n",
    "#         label_text = f\"{assigned_id}\"\n",
    "\n",
    "#         if class_name == \"car\":\n",
    "#             car_boxes.append((xmin, ymin, xmax, ymax))\n",
    "#         elif class_name == \"light\":\n",
    "#             light_boxes.append((xmin, ymin, xmax, ymax))\n",
    "#             # 라이트 바운딩 박스에서 RGB 값 추출 및 트래킹이 시작된 경우만 기록\n",
    "#             if track.is_confirmed() and track.time_since_update == 0:\n",
    "#                 light_region = frame[ymin:ymax, xmin:xmax]\n",
    "#                 avg_color = cv2.mean(light_region)[:3]  # BGR을 RGB로 변환\n",
    "#                 light_rgb = (int(avg_color[2]), int(avg_color[1]), int(avg_color[0]))\n",
    "#                 light_ids_rgb.append((assigned_id, light_rgb))\n",
    "\n",
    "#             # RGB 값 기록\n",
    "#             if not light_rgb_history[assigned_id]:\n",
    "#                 light_rgb_history[assigned_id] = [(None, None, None)] * frame_count\n",
    "#             light_rgb_history[assigned_id].append(light_rgb)\n",
    "            \n",
    "#         # 바운딩 박스 및 라벨 그리기\n",
    "#         cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), box_color, 2)\n",
    "#         cv2.putText(frame, label_text, (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, WHITE, 2)\n",
    "\n",
    "#     # FPS 계산 및 표시\n",
    "#     end = datetime.datetime.now()\n",
    "#     total = (end - start).total_seconds()\n",
    "#     fps = f'FPS: {1 / total:.2f}'\n",
    "#     cv2.putText(frame, f'FPS: {1 / total:.2f} (Time: {frame_count / 30:.2f}s)', (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "#     # 프레임 수 표시\n",
    "#     cv2.putText(frame, f'Frame: {frame_count} (Time: {frame_count / 30:.2f}s)', (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "\n",
    "#     # 결과 프레임 저장\n",
    "#     out.write(frame)\n",
    "\n",
    "#     # 결과 프레임 표시\n",
    "#     cv2.imshow('frame', frame)\n",
    "\n",
    "#     if cv2.waitKey(1) == ord('q'):\n",
    "#         break\n",
    "\n",
    "#     frame_count += 1\n",
    "\n",
    "# # 비디오 저장 종료\n",
    "# out.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot average RGB values and variance of average RGB values for each light\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# light_rgb_history = {k: v for k, v in light_rgb_history.items() if v}  # Keep only lights that have tracking history\n",
    "# num_lights = len(light_rgb_history)\n",
    "# fig, axes = plt.subplots(num_lights, 4, figsize=(24, 6 * num_lights), sharex=True)\n",
    "# if num_lights == 1:\n",
    "#     axes = [axes]\n",
    "\n",
    "# # Calculate the global maximum variance to set y-axis limits consistently across all variance plots\n",
    "# global_max_variance = max(\n",
    "#     [\n",
    "#         np.var([val for val in [(r, g, b) if (r, g, b) != (None, None, None) else None for r, g, b in rgb_values][:i] if val is not None])\n",
    "#         for rgb_values in light_rgb_history.values()\n",
    "#         for i in range(1, len(rgb_values) + 1)\n",
    "#         if len([val for val in [(r, g, b) if (r, g, b) != (None, None, None) else None for r, g, b in rgb_values][:i] if val is not None]) > 1\n",
    "#     ],\n",
    "#     default=1\n",
    "# )\n",
    "\n",
    "# for (light_id, rgb_values), ax_pair in zip(light_rgb_history.items(), axes):\n",
    "#     ax_rgb, ax_diff_rg_rb, ax_avg, ax_avg_var = ax_pair\n",
    "\n",
    "#     # Plot RGB values\n",
    "#     r_values = [r if (r, g, b) != (None, None, None) else None for r, g, b in rgb_values]\n",
    "#     g_values = [g if (r, g, b) != (None, None, None) else None for r, g, b in rgb_values]\n",
    "#     b_values = [b if (r, g, b) != (None, None, None) else None for r, g, b in rgb_values]\n",
    "#     ax_rgb.plot(range(len(r_values)), r_values, label=f'{light_id} - R', color='r')\n",
    "#     ax_rgb.plot(range(len(g_values)), g_values, label=f'{light_id} - G', color='g')\n",
    "#     ax_rgb.plot(range(len(b_values)), b_values, label=f'{light_id} - B', color='b')\n",
    "#     ax_rgb.set_xlabel('Frame')\n",
    "#     ax_rgb.set_ylabel('RGB Value')\n",
    "#     ax_rgb.set_ylim(0, 255)  # Set y-axis limit to ensure consistent scaling for RGB values\n",
    "#     ax_rgb.set_title(f'RGB Values Over Frames for {light_id}')\n",
    "#     ax_rgb.legend()\n",
    "\n",
    "#     # Calculate R-G and R-B differences\n",
    "#     rg_diff = [r - g if (r is not None and g is not None) else None for r, g in zip(r_values, g_values)]\n",
    "#     rb_diff = [r - b if (r is not None and b is not None) else None for r, b in zip(r_values, b_values)]\n",
    "\n",
    "#     # Plot R-G and R-B differences\n",
    "#     ax_diff_rg_rb.plot(range(len(rg_diff)), rg_diff, label=f'{light_id} - R-G', color='purple')\n",
    "#     ax_diff_rg_rb.plot(range(len(rb_diff)), rb_diff, label=f'{light_id} - R-B', color='orange')\n",
    "#     ax_diff_rg_rb.set_xlabel('Frame')\n",
    "#     ax_diff_rg_rb.set_ylabel('Difference Value')\n",
    "#     ax_diff_rg_rb.set_ylim(min([val for val in (rg_diff + rb_diff) if val is not None]) - 10, max([val for val in (rg_diff + rb_diff) if val is not None]) + 10)  # Set y-axis limit to ensure consistent scaling for difference values\n",
    "#     ax_diff_rg_rb.set_title(f'R-G and R-B Differences Over Frames for {light_id}')\n",
    "#     ax_diff_rg_rb.legend()\n",
    "\n",
    "#     # Calculate average RGB values per frame\n",
    "#     avg_rgb_values = [(r + g + b) / 3 if (r, g, b) != (None, None, None) else None for r, g, b in rgb_values]\n",
    "    \n",
    "#     # Plot average RGB values\n",
    "#     ax_avg.plot(range(len(avg_rgb_values)), avg_rgb_values, label=f'{light_id} - Avg RGB', color='b')\n",
    "#     ax_avg.set_xlabel('Frame')\n",
    "#     ax_avg.set_ylabel('Average RGB Value')\n",
    "#     ax_avg.set_ylim(0, 255)  # Set y-axis limit to ensure consistent scaling for average RGB values\n",
    "#     ax_avg.set_title(f'Average RGB Values Over Frames for {light_id}')\n",
    "#     ax_avg.legend()\n",
    "\n",
    "#     # Calculate variance of average RGB values over the frames\n",
    "#     avg_variances = []\n",
    "#     for i in range(1, len(avg_rgb_values) + 1):\n",
    "#         valid_values = [val for val in avg_rgb_values[i-10:i+11] if val is not None]\n",
    "#         if len(valid_values) > 1:\n",
    "#             avg_variances.append(np.var(valid_values))\n",
    "#         else:\n",
    "#             avg_variances.append(None)\n",
    "    \n",
    "#     # Plot variance of average RGB values with y-axis scaled to the global maximum variance\n",
    "#     ax_avg_var.plot(range(len(avg_variances)), avg_variances, label=f'{light_id} - Variance of Avg RGB', color='c')\n",
    "#     ax_avg_var.set_ylim(0, global_max_variance+20)  # Set y-axis limit to the global maximum variance value\n",
    "#     ax_avg_var.set_xlabel('Frame')\n",
    "#     ax_avg_var.set_ylabel('Variance')\n",
    "#     ax_avg_var.set_title(f'Variance of Average RGB Values Over Frames for {light_id}')\n",
    "#     ax_avg_var.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  on-off 알고리즘 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "GREEN = (0, 255, 0)\n",
    "WHITE = (255, 255, 255)\n",
    "RED = (0, 0, 255)\n",
    "\n",
    "# 클래스 정보 입력\n",
    "with open('/Users/kimhyeonjeong/Documents/2024-2/OD/code/yolo_class.txt', 'r') as coco128:\n",
    "    class_list = coco128.read().split('\\n')\n",
    "\n",
    "# YOLO 모델과 DeepSort 초기화\n",
    "model = YOLO('/Users/kimhyeonjeong/Documents/2024-2/OD/code/best.pt')\n",
    "tracker = DeepSort(max_age=50)\n",
    "\n",
    "# 이미지 폴더 설정\n",
    "image_folder_path = '/Users/kimhyeonjeong/Documents/2024-2/OD/code/bel12'  # 이미지 폴더 경로\n",
    "file_names = os.listdir(image_folder_path)\n",
    "image_files = [f for f in file_names if f.endswith(('.jpg', '.png'))]\n",
    "image_files.sort()\n",
    "\n",
    "# 트래킹 ID 및 라이트 RGB 기록을 저장할 딕셔너리 초기화\n",
    "class_track_ids = {}\n",
    "light_rgb_history = defaultdict(list)\n",
    "\n",
    "# 비디오 저장 설정\n",
    "output_video_path = '/Users/kimhyeonjeong/Documents/2024-2/OD/code/output/bel12_output.mp4'\n",
    "frame_width, frame_height = cv2.imread(os.path.join(image_folder_path, image_files[0])).shape[1], cv2.imread(os.path.join(image_folder_path, image_files[0])).shape[0]\n",
    "out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), 30.0, (frame_width, frame_height))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 176.0ms\n",
      "Speed: 1.6ms preprocess, 176.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 165.5ms\n",
      "Speed: 1.5ms preprocess, 165.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 202.5ms\n",
      "Speed: 1.3ms preprocess, 202.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 170.2ms\n",
      "Speed: 1.4ms preprocess, 170.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 204.1ms\n",
      "Speed: 1.6ms preprocess, 204.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 168.8ms\n",
      "Speed: 1.3ms preprocess, 168.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 177.4ms\n",
      "Speed: 2.0ms preprocess, 177.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 182.2ms\n",
      "Speed: 1.6ms preprocess, 182.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 3 Lights, 188.5ms\n",
      "Speed: 1.5ms preprocess, 188.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 3 Lights, 163.5ms\n",
      "Speed: 1.5ms preprocess, 163.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 2 Lights, 176.4ms\n",
      "Speed: 1.4ms preprocess, 176.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 2 Lights, 185.5ms\n",
      "Speed: 1.2ms preprocess, 185.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 3 Lights, 173.9ms\n",
      "Speed: 1.3ms preprocess, 173.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 3 Lights, 172.4ms\n",
      "Speed: 1.4ms preprocess, 172.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 185.6ms\n",
      "Speed: 1.3ms preprocess, 185.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 267.2ms\n",
      "Speed: 2.1ms preprocess, 267.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 240.5ms\n",
      "Speed: 1.6ms preprocess, 240.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 182.9ms\n",
      "Speed: 1.9ms preprocess, 182.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 171.9ms\n",
      "Speed: 1.7ms preprocess, 171.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 177.5ms\n",
      "Speed: 1.4ms preprocess, 177.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 167.1ms\n",
      "Speed: 1.9ms preprocess, 167.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 220.0ms\n",
      "Speed: 1.5ms preprocess, 220.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 165.1ms\n",
      "Speed: 1.3ms preprocess, 165.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 308.4ms\n",
      "Speed: 3.3ms preprocess, 308.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 318.5ms\n",
      "Speed: 3.5ms preprocess, 318.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 323.9ms\n",
      "Speed: 3.8ms preprocess, 323.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 4 Lights, 312.6ms\n",
      "Speed: 2.6ms preprocess, 312.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 182.2ms\n",
      "Speed: 1.5ms preprocess, 182.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 301.5ms\n",
      "Speed: 4.4ms preprocess, 301.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 302.4ms\n",
      "Speed: 2.6ms preprocess, 302.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 325.0ms\n",
      "Speed: 3.2ms preprocess, 325.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 291.0ms\n",
      "Speed: 2.4ms preprocess, 291.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 307.4ms\n",
      "Speed: 3.1ms preprocess, 307.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 288.5ms\n",
      "Speed: 3.3ms preprocess, 288.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Cars, 4 Lights, 305.6ms\n",
      "Speed: 3.2ms preprocess, 305.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 4 Lights, 322.7ms\n",
      "Speed: 4.2ms preprocess, 322.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 4 Lights, 320.9ms\n",
      "Speed: 2.9ms preprocess, 320.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 4 Lights, 294.0ms\n",
      "Speed: 3.0ms preprocess, 294.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 4 Lights, 302.7ms\n",
      "Speed: 3.8ms preprocess, 302.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 4 Lights, 307.2ms\n",
      "Speed: 4.3ms preprocess, 307.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 4 Lights, 309.5ms\n",
      "Speed: 5.8ms preprocess, 309.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 4 Lights, 314.0ms\n",
      "Speed: 6.0ms preprocess, 314.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 5 Lights, 298.4ms\n",
      "Speed: 3.4ms preprocess, 298.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 5 Lights, 329.1ms\n",
      "Speed: 4.2ms preprocess, 329.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 5 Lights, 311.8ms\n",
      "Speed: 2.6ms preprocess, 311.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 299.4ms\n",
      "Speed: 4.8ms preprocess, 299.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 5 Lights, 339.7ms\n",
      "Speed: 3.0ms preprocess, 339.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 5 Lights, 321.4ms\n",
      "Speed: 2.0ms preprocess, 321.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 5 Lights, 301.3ms\n",
      "Speed: 2.9ms preprocess, 301.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 300.8ms\n",
      "Speed: 9.5ms preprocess, 300.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 5 Lights, 294.4ms\n",
      "Speed: 2.0ms preprocess, 294.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 5 Lights, 299.3ms\n",
      "Speed: 2.6ms preprocess, 299.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 339.6ms\n",
      "Speed: 4.0ms preprocess, 339.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 310.7ms\n",
      "Speed: 4.1ms preprocess, 310.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 5 Lights, 288.4ms\n",
      "Speed: 29.7ms preprocess, 288.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 5 Lights, 325.5ms\n",
      "Speed: 3.1ms preprocess, 325.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 5 Lights, 286.2ms\n",
      "Speed: 9.4ms preprocess, 286.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 5 Lights, 327.3ms\n",
      "Speed: 3.8ms preprocess, 327.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 4 Lights, 325.2ms\n",
      "Speed: 13.3ms preprocess, 325.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 4 Lights, 313.2ms\n",
      "Speed: 9.3ms preprocess, 313.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 4 Lights, 321.1ms\n",
      "Speed: 5.7ms preprocess, 321.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 4 Lights, 306.7ms\n",
      "Speed: 6.4ms preprocess, 306.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 4 Lights, 307.7ms\n",
      "Speed: 3.1ms preprocess, 307.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 4 Lights, 317.6ms\n",
      "Speed: 3.9ms preprocess, 317.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 4 Lights, 300.3ms\n",
      "Speed: 3.7ms preprocess, 300.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 4 Lights, 314.7ms\n",
      "Speed: 3.0ms preprocess, 314.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 4 Lights, 305.4ms\n",
      "Speed: 5.9ms preprocess, 305.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 311.8ms\n",
      "Speed: 5.4ms preprocess, 311.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 342.3ms\n",
      "Speed: 6.3ms preprocess, 342.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 306.2ms\n",
      "Speed: 4.6ms preprocess, 306.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 307.6ms\n",
      "Speed: 2.6ms preprocess, 307.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 311.7ms\n",
      "Speed: 3.3ms preprocess, 311.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 286.2ms\n",
      "Speed: 23.2ms preprocess, 286.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 291.0ms\n",
      "Speed: 7.9ms preprocess, 291.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 301.4ms\n",
      "Speed: 5.3ms preprocess, 301.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 324.3ms\n",
      "Speed: 5.5ms preprocess, 324.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 4 Lights, 283.8ms\n",
      "Speed: 7.7ms preprocess, 283.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 5 Lights, 322.4ms\n",
      "Speed: 8.2ms preprocess, 322.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 4 Lights, 342.3ms\n",
      "Speed: 4.6ms preprocess, 342.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 4 Lights, 319.3ms\n",
      "Speed: 2.3ms preprocess, 319.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 4 Lights, 306.0ms\n",
      "Speed: 4.9ms preprocess, 306.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 4 Lights, 311.2ms\n",
      "Speed: 2.7ms preprocess, 311.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 302.0ms\n",
      "Speed: 12.9ms preprocess, 302.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 309.4ms\n",
      "Speed: 1.5ms preprocess, 309.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 307.3ms\n",
      "Speed: 3.8ms preprocess, 307.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 316.6ms\n",
      "Speed: 3.6ms preprocess, 316.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 324.5ms\n",
      "Speed: 4.0ms preprocess, 324.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 319.6ms\n",
      "Speed: 3.2ms preprocess, 319.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 297.4ms\n",
      "Speed: 3.3ms preprocess, 297.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 310.1ms\n",
      "Speed: 2.7ms preprocess, 310.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 307.3ms\n",
      "Speed: 3.6ms preprocess, 307.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 311.7ms\n",
      "Speed: 9.7ms preprocess, 311.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 305.2ms\n",
      "Speed: 3.0ms preprocess, 305.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 294.3ms\n",
      "Speed: 7.3ms preprocess, 294.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 308.3ms\n",
      "Speed: 4.0ms preprocess, 308.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 5 Lights, 319.3ms\n",
      "Speed: 3.3ms preprocess, 319.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 317.7ms\n",
      "Speed: 4.5ms preprocess, 317.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 295.5ms\n",
      "Speed: 2.9ms preprocess, 295.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 326.5ms\n",
      "Speed: 6.5ms preprocess, 326.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 313.2ms\n",
      "Speed: 4.4ms preprocess, 313.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 315.1ms\n",
      "Speed: 17.2ms preprocess, 315.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 340.6ms\n",
      "Speed: 6.2ms preprocess, 340.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 323.5ms\n",
      "Speed: 4.1ms preprocess, 323.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 7 Lights, 309.9ms\n",
      "Speed: 2.2ms preprocess, 309.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 7 Lights, 321.8ms\n",
      "Speed: 2.5ms preprocess, 321.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 334.2ms\n",
      "Speed: 3.7ms preprocess, 334.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 313.2ms\n",
      "Speed: 6.2ms preprocess, 313.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 331.8ms\n",
      "Speed: 2.8ms preprocess, 331.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 312.6ms\n",
      "Speed: 11.3ms preprocess, 312.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 305.5ms\n",
      "Speed: 1.9ms preprocess, 305.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 307.4ms\n",
      "Speed: 1.2ms preprocess, 307.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 298.7ms\n",
      "Speed: 4.1ms preprocess, 298.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 304.1ms\n",
      "Speed: 4.2ms preprocess, 304.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 304.4ms\n",
      "Speed: 2.0ms preprocess, 304.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 322.2ms\n",
      "Speed: 5.9ms preprocess, 322.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 325.0ms\n",
      "Speed: 5.1ms preprocess, 325.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 320.5ms\n",
      "Speed: 3.9ms preprocess, 320.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 304.5ms\n",
      "Speed: 3.2ms preprocess, 304.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 308.1ms\n",
      "Speed: 3.3ms preprocess, 308.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 290.7ms\n",
      "Speed: 4.8ms preprocess, 290.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 315.8ms\n",
      "Speed: 4.1ms preprocess, 315.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 299.0ms\n",
      "Speed: 3.5ms preprocess, 299.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 336.2ms\n",
      "Speed: 6.6ms preprocess, 336.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 328.1ms\n",
      "Speed: 8.2ms preprocess, 328.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 313.7ms\n",
      "Speed: 2.6ms preprocess, 313.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 307.2ms\n",
      "Speed: 2.7ms preprocess, 307.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 303.0ms\n",
      "Speed: 6.0ms preprocess, 303.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 311.8ms\n",
      "Speed: 3.6ms preprocess, 311.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 294.3ms\n",
      "Speed: 4.3ms preprocess, 294.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 304.4ms\n",
      "Speed: 7.3ms preprocess, 304.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 300.8ms\n",
      "Speed: 1.9ms preprocess, 300.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 303.0ms\n",
      "Speed: 4.6ms preprocess, 303.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 307.6ms\n",
      "Speed: 4.4ms preprocess, 307.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 312.3ms\n",
      "Speed: 5.6ms preprocess, 312.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 333.8ms\n",
      "Speed: 5.4ms preprocess, 333.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 310.2ms\n",
      "Speed: 2.5ms preprocess, 310.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 310.3ms\n",
      "Speed: 3.3ms preprocess, 310.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 320.2ms\n",
      "Speed: 2.6ms preprocess, 320.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 312.5ms\n",
      "Speed: 3.0ms preprocess, 312.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 320.2ms\n",
      "Speed: 3.8ms preprocess, 320.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 289.6ms\n",
      "Speed: 4.1ms preprocess, 289.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 299.6ms\n",
      "Speed: 2.7ms preprocess, 299.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 309.9ms\n",
      "Speed: 4.8ms preprocess, 309.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 309.4ms\n",
      "Speed: 3.7ms preprocess, 309.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 295.8ms\n",
      "Speed: 10.5ms preprocess, 295.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 304.4ms\n",
      "Speed: 3.4ms preprocess, 304.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 299.4ms\n",
      "Speed: 5.1ms preprocess, 299.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 307.4ms\n",
      "Speed: 4.0ms preprocess, 307.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 309.2ms\n",
      "Speed: 2.0ms preprocess, 309.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 298.2ms\n",
      "Speed: 7.3ms preprocess, 298.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 293.5ms\n",
      "Speed: 2.3ms preprocess, 293.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 309.1ms\n",
      "Speed: 3.1ms preprocess, 309.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 306.4ms\n",
      "Speed: 3.8ms preprocess, 306.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 297.1ms\n",
      "Speed: 5.9ms preprocess, 297.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 305.2ms\n",
      "Speed: 2.3ms preprocess, 305.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 312.4ms\n",
      "Speed: 3.5ms preprocess, 312.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 311.8ms\n",
      "Speed: 3.1ms preprocess, 311.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 312.0ms\n",
      "Speed: 5.6ms preprocess, 312.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 311.7ms\n",
      "Speed: 7.8ms preprocess, 311.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 304.9ms\n",
      "Speed: 5.1ms preprocess, 304.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 305.3ms\n",
      "Speed: 2.8ms preprocess, 305.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 296.7ms\n",
      "Speed: 3.9ms preprocess, 296.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 302.3ms\n",
      "Speed: 2.8ms preprocess, 302.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 291.5ms\n",
      "Speed: 2.5ms preprocess, 291.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 308.8ms\n",
      "Speed: 6.2ms preprocess, 308.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 312.1ms\n",
      "Speed: 2.1ms preprocess, 312.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 311.1ms\n",
      "Speed: 8.4ms preprocess, 311.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 290.1ms\n",
      "Speed: 1.8ms preprocess, 290.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 316.9ms\n",
      "Speed: 2.4ms preprocess, 316.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 308.5ms\n",
      "Speed: 2.7ms preprocess, 308.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 314.5ms\n",
      "Speed: 2.9ms preprocess, 314.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 313.4ms\n",
      "Speed: 3.1ms preprocess, 313.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 292.8ms\n",
      "Speed: 5.6ms preprocess, 292.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 307.6ms\n",
      "Speed: 3.6ms preprocess, 307.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 309.5ms\n",
      "Speed: 2.2ms preprocess, 309.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 345.6ms\n",
      "Speed: 3.8ms preprocess, 345.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 301.1ms\n",
      "Speed: 2.7ms preprocess, 301.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 311.2ms\n",
      "Speed: 1.9ms preprocess, 311.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 308.9ms\n",
      "Speed: 5.9ms preprocess, 308.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 313.4ms\n",
      "Speed: 5.2ms preprocess, 313.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 304.1ms\n",
      "Speed: 3.6ms preprocess, 304.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 310.1ms\n",
      "Speed: 1.9ms preprocess, 310.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 320.4ms\n",
      "Speed: 4.4ms preprocess, 320.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 319.8ms\n",
      "Speed: 5.1ms preprocess, 319.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 310.1ms\n",
      "Speed: 2.5ms preprocess, 310.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 298.1ms\n",
      "Speed: 3.8ms preprocess, 298.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 306.7ms\n",
      "Speed: 3.3ms preprocess, 306.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 302.1ms\n",
      "Speed: 3.6ms preprocess, 302.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 311.7ms\n",
      "Speed: 4.2ms preprocess, 311.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 307.9ms\n",
      "Speed: 5.1ms preprocess, 307.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 314.8ms\n",
      "Speed: 4.6ms preprocess, 314.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 342.8ms\n",
      "Speed: 4.4ms preprocess, 342.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 301.6ms\n",
      "Speed: 2.5ms preprocess, 301.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 309.7ms\n",
      "Speed: 3.1ms preprocess, 309.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 285.3ms\n",
      "Speed: 4.2ms preprocess, 285.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 325.4ms\n",
      "Speed: 2.6ms preprocess, 325.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 306.5ms\n",
      "Speed: 2.6ms preprocess, 306.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 305.6ms\n",
      "Speed: 4.6ms preprocess, 305.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 298.3ms\n",
      "Speed: 6.3ms preprocess, 298.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 303.9ms\n",
      "Speed: 2.9ms preprocess, 303.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Cars, 6 Lights, 301.9ms\n",
      "Speed: 3.0ms preprocess, 301.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def update_light_box_color(light_rgb_history, frame_count, assigned_id):\n",
    "    # 10프레임 단위로 R-G, R-B 계산 및 분산/shift mean 계산\n",
    "    if frame_count % 10 == 0 and len(light_rgb_history[assigned_id]) >= 10:\n",
    "        last_10_frames = light_rgb_history[assigned_id][-10:]\n",
    "        r_values = [rgb[0] for rgb in last_10_frames if rgb != (None, None, None)]\n",
    "        g_values = [rgb[1] for rgb in last_10_frames if rgb != (None, None, None)]\n",
    "        b_values = [rgb[2] for rgb in last_10_frames if rgb != (None, None, None)]\n",
    "\n",
    "        if len(r_values) == 10:\n",
    "            r_g_diff = [r - g for r, g in zip(r_values, g_values)]\n",
    "            r_b_diff = [r - b for r, b in zip(r_values, b_values)]\n",
    "\n",
    "            variance_r_g = np.var(r_g_diff)\n",
    "            variance_r_b = np.var(r_b_diff)\n",
    "\n",
    "            if variance_r_g > VARIANCE_THRESHOLD or variance_r_b > VARIANCE_THRESHOLD:\n",
    "                return RED\n",
    "            else:\n",
    "                shift_mean_r = np.mean(np.diff(r_values))\n",
    "                if shift_mean_r > SHIFT_MEAN_THRESHOLD:\n",
    "                    return RED\n",
    "                else:\n",
    "                    return GREEN\n",
    "    return GREEN\n",
    "\n",
    "# Additional variables\n",
    "THRESHOLD_DIFF = 50\n",
    "VARIANCE_THRESHOLD = 100\n",
    "SHIFT_MEAN_THRESHOLD = 30\n",
    "\n",
    "# Initialize light_ids_rgb\n",
    "light_ids_rgb = []\n",
    "\n",
    "# Update color for bounding boxes based on R-G, R-B difference and variance\n",
    "frame_count = 0\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(image_folder_path, image_file)\n",
    "    frame = cv2.imread(image_path)\n",
    "    if frame is None:\n",
    "        print(f\"Warning: Could not load image {image_file}\")\n",
    "        continue\n",
    "\n",
    "    # YOLO 모델을 사용하여 객체 감지 수행\n",
    "    detection = model.predict(source=[frame], save=False)[0]\n",
    "    results = []\n",
    "\n",
    "    for data in detection.boxes.data.tolist():  # data : [xmin, ymin, xmax, ymax, confidence_score, class_id]\n",
    "        confidence = float(data[4])\n",
    "        if confidence < CONFIDENCE_THRESHOLD:\n",
    "            continue\n",
    "\n",
    "        xmin, ymin, xmax, ymax = int(data[0]), int(data[1]), int(data[2]), int(data[3])\n",
    "        width = xmax - xmin\n",
    "        height = ymax - ymin\n",
    "        label = int(data[5])\n",
    "        class_name = class_list[label]\n",
    "\n",
    "        # 클래스별 트래킹 ID 관리\n",
    "        if class_name not in class_track_ids:\n",
    "            class_track_ids[class_name] = {}\n",
    "\n",
    "        bbox = (xmin, ymin, width, height)\n",
    "        results.append([bbox, confidence, label])\n",
    "\n",
    "    # DeepSort를 사용하여 트래킹 업데이트\n",
    "    tracks = tracker.update_tracks(results, frame=frame)\n",
    "\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "\n",
    "        track_id = track.track_id\n",
    "        ltrb = track.to_ltrb()\n",
    "        label = track.det_class\n",
    "        class_name = class_list[label]\n",
    "\n",
    "        if track_id not in class_track_ids[class_name]:\n",
    "            class_track_ids[class_name][track_id] = f\"{class_name}-{len(class_track_ids[class_name]) + 1}\"\n",
    "\n",
    "        assigned_id = class_track_ids[class_name][track_id]\n",
    "        xmin, ymin, xmax, ymax = int(ltrb[0]), int(ltrb[1]), int(ltrb[2]), int(ltrb[3])\n",
    "        label_text = f\"{assigned_id}\"\n",
    "\n",
    "        box_color = GREEN\n",
    "        if class_name == \"light\":\n",
    "            light_region = frame[ymin:ymax, xmin:xmax]\n",
    "            avg_color = cv2.mean(light_region)[:3]  # BGR to RGB\n",
    "            light_rgb = (int(avg_color[2]), int(avg_color[1]), int(avg_color[0]))\n",
    "            light_ids_rgb.append((assigned_id, light_rgb))\n",
    "\n",
    "            # RGB 값 기록\n",
    "            if not light_rgb_history[assigned_id]:\n",
    "                light_rgb_history[assigned_id] = [(None, None, None)] * frame_count\n",
    "            light_rgb_history[assigned_id].append(light_rgb)\n",
    "\n",
    "            # Update box color using the function\n",
    "            box_color = update_light_box_color(light_rgb_history, frame_count, assigned_id)\n",
    "\n",
    "        # Draw bounding box and label\n",
    "        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), box_color, 2)\n",
    "        cv2.putText(frame, label_text, (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, WHITE, 2)\n",
    "\n",
    "    # 결과 프레임 저장 및 표시\n",
    "    out.write(frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# 비디오 저장 종료\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "object_counters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
